import pandas as pd
from .eda import eda
from .feature_engineering import feature_engineering
from .partitioning import partitioning
from .numeric_conversion import numeric_conversion
from .scaling import scaling
from .model_baseline import model_baseline
from .shap_explainability import shap_explainability
from .shap_selection import shap_selection
from .feature_correlation import feature_correlation
from .feature_select_cluster import feature_select_cluster
from .feature_select_threshold import feature_select_threshold
from .hyperparameter_tuning import hyperparameter_tuning
from .final_model import final_model


class MLPipeline:
    """
    Master orchestration object for configuration-driven ML pipeline execution.
    Stores full state, supports hash-based tracking, checkpointing, and recovery.
    """

    def __init__(self, config: dict):
        self.config = config
        self.dataframes: dict[str, pd.DataFrame] = {}
        self.paths: dict[str, str] = {}
        self.hashes: dict[str, str] = {}
        self.models: dict[str, object] = {}
        self.metrics: dict[str, dict] = {}
        # self.metadata: dict[str, dict] = {}
        self.artifacts: dict[str, dict] = {}  # Store paths to all artifacts generated by each step
        self.transformations: dict[str, dict] = {}  # Store transformation parameters for each step
        self.artifact_dir = "artifacts"
        self.artifact_dirs: list[str] = [
            "mlruns",
            "artifacts",
            "artifacts/eda",
            "artifacts/step1",
            "artifacts/step2",
            "artifacts/step3",
            "artifacts/step4",
            "artifacts/step5",
            "artifacts/step6",
            "artifacts/step7",
            "artifacts/step8",
            "artifacts/step9",
            "artifacts/step10",
            "artifacts/step11",
            "artifacts/step12"
            ]
        # Bind the imported functions to this instance
        self.eda = lambda: eda(self)
        self.feature_engineering = lambda: feature_engineering(self)
        self.partitioning = lambda: partitioning(self)
        self.numeric_conversion = lambda: numeric_conversion(self)
        self.scaling = lambda: scaling(self)
        self.model_baseline = lambda: model_baseline(self)
        self.shap_explainability = lambda: shap_explainability(self)
        self.shap_selection = lambda: shap_selection(self)
        self.feature_correlation = lambda: feature_correlation(self)
        self.feature_select_cluster = lambda: feature_select_cluster(self)
        self.feature_select_threshold = lambda: feature_select_threshold(self)
        self.hyperparameter_tuning = lambda: hyperparameter_tuning(self)
        self.final_model = lambda: final_model(self)

    def load_data(self, db_path: str = "fraud_poc.db") -> pd.DataFrame:
        """
        Load and merge raw data from SQLite into a single dataframe.
        """
        import sqlite3
        conn = sqlite3.connect(db_path)
        df_clients = pd.read_sql("SELECT * FROM clients", conn)
        df_merchants = pd.read_sql("SELECT * FROM merchants", conn)
        df_tx = pd.read_sql("SELECT * FROM transactions", conn)
        conn.close()

        df_clients.rename(columns={"account_creation_date": "account_creation_date_client"}, inplace=True)
        df_merchants.rename(columns={"account_creation_date": "account_creation_date_merchant"}, inplace=True)

        return df_tx.merge(df_clients, on="client_id").merge(df_merchants, on="merchant_id")

    def run_all(self) -> None:
        """
        Execute all pipeline steps in sequence, storing full internal state.
        """
        self.eda()
        self.feature_engineering()
        self.partitioning()
        self.numeric_conversion()
        self.scaling()
        self.model_baseline()

    
    def run_later(self)-> None:
        self.shap_explainability()
        self.shap_selection()
        self.feature_correlation()
        if self.config["use_cluster_select"][0]:
            self.feature_select_cluster()
        else:
            self.feature_select_threshold()
        self.hyperparameter_tuning()
        self.final_model()
        
        # Save the final state of the pipeline
        # self.save_state()